Traceback (most recent call last):
  File "/home/jovyan/jonglae/Retry1/Segmentation/SAM_NoDataAug2.py", line 189, in <module>
    main()
  File "/home/jovyan/jonglae/Retry1/Segmentation/SAM_NoDataAug2.py", line 186, in main
    test_sam_with_image_only(predictor, test_image_folder, output_folder, device='cuda')
  File "/home/jovyan/jonglae/Retry1/Segmentation/SAM_NoDataAug2.py", line 152, in test_sam_with_image_only
    predictor.set_image(preprocessed_image)
  File "/home/jovyan/SAM_Model/segment_anything/predictor.py", line 56, in set_image
    input_image = self.transform.apply_image(image)
  File "/home/jovyan/SAM_Model/segment_anything/utils/transforms.py", line 31, in apply_image
    return np.array(resize(to_pil_image(image), target_size))
  File "/home/jovyan/.conda/envs/aipbase/lib/python3.10/site-packages/torchvision/transforms/functional.py", line 274, in to_pil_image
    raise ValueError(f"pic should be 2/3 dimensional. Got {pic.ndim} dimensions.")
ValueError: pic should be 2/3 dimensional. Got 4 dimensions.
