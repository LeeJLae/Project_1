Traceback (most recent call last):
  File "/home/jovyan/jonglae/Retry1/Segmentation/SAM_NoDataAug.py", line 191, in <module>
    main()
  File "/home/jovyan/jonglae/Retry1/Segmentation/SAM_NoDataAug.py", line 177, in main
    train_sam_with_measurement(
  File "/home/jovyan/jonglae/Retry1/Segmentation/SAM_NoDataAug.py", line 117, in train_sam_with_measurement
    predictor.set_image(preprocessed_images)
  File "/home/jovyan/SAM_Model/segment_anything/predictor.py", line 56, in set_image
    input_image = self.transform.apply_image(image)
  File "/home/jovyan/SAM_Model/segment_anything/utils/transforms.py", line 31, in apply_image
    return np.array(resize(to_pil_image(image), target_size))
  File "/home/jovyan/.conda/envs/aipbase/lib/python3.10/site-packages/torchvision/transforms/functional.py", line 274, in to_pil_image
    raise ValueError(f"pic should be 2/3 dimensional. Got {pic.ndim} dimensions.")
ValueError: pic should be 2/3 dimensional. Got 4 dimensions
