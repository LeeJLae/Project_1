import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import cv2
import random
from scipy import stats
import torchvision.models as models
import os

# EnhancedRotNetWithResNet 정의
class EnhancedRotNetWithResNet(nn.Module):
    def __init__(self):
        super(EnhancedRotNetWithResNet, self).__init__()
        self.resnet = models.resnet18(weights=None)
        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.resnet.fc = nn.Identity()
        self.fc1 = nn.Linear(512, 128)
        self.dropout1 = nn.Dropout(0.5)
        self.fc2 = nn.Linear(128, 64)
        self.dropout2 = nn.Dropout(0.5)
        self.fc3 = nn.Linear(64, 1)

    def forward(self, x):
        x = self.resnet(x)
        x = F.relu(self.fc1(x))
        x = self.dropout1(x)
        x = F.relu(self.fc2(x))
        x = self.dropout2(x)
        return self.fc3(x)

# 파라미터 불러오기 및 키 수정 후 적용
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = EnhancedRotNetWithResNet().to(device)
# 파라미터 불러오기
state_dict = torch.load(f"/home/jovyan/resnet_pretrain/resnet18.pth", map_location="cpu",weights_only=True)
# # 키수정
# state_dict = {k.replace("module.", ""): v for k, v in state_dict.items()}
# # 제거
# state_dict = {'patch_embed.backbone.' + k: v for k, v in state_dict.items()}
# msg = model.load_state_dict(state_dict, strict=False)
# print('weight loading message:', msg)

# 모델의 기존 키와 맞추기 위해 필요한 부분만 남기거나 불필요한 키 제거
model_dict = model.state_dict()
pretrained_dict = {k.replace("patch_embed.backbone.", ""): v for k, v in state_dict.items() if k in model_dict}
model_dict.update(pretrained_dict)

msg = model.load_state_dict(model_dict, strict=False)
print('weight loading message:', msg)


# 이미지 크기 맞추기 함수
def resize_and_pad(image, target_size=(128, 128)):
    h, w = image.shape[:2]
    scale = min(target_size[0] / h, target_size[1] / w)
    new_w, new_h = int(w * scale), int(h * scale)
    resized_image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)
    pad_w = (target_size[1] - new_w) // 2
    pad_h = (target_size[0] - new_h) // 2
    return cv2.copyMakeBorder(resized_image, pad_h, target_size[0] - new_h - pad_h, pad_w, target_size[1] - new_w - pad_w, cv2.BORDER_CONSTANT, value=[0, 0, 0])

# 회전 함수
def rotate_image(image, angle):
    (h, w) = image.shape[:2]
    center = (w // 2, h // 2)
    avg_pixel_value = int(np.mean(image))
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    return cv2.warpAffine(image, M, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=avg_pixel_value)

# 데이터셋 클래스 정의
class RotNetDataset(Dataset):
    def __init__(self, folder_path, num_augmentations=30, rotation_range=(-50, 50), crop_size=(100, 100), brightness_range=(0.5, 1.5)):
        self.images = self.load_images(folder_path)
        self.num_augmentations = num_augmentations
        self.rotation_range = rotation_range
        self.crop_size = crop_size
        self.brightness_range = brightness_range
        self.augmented_data = self.augment_images()

    def load_images(self, folder_path):
        images = []
        for filename in os.listdir(folder_path):
            if filename.endswith(('.png', '.jpg', '.jpeg','.JPG')):
                image = cv2.imread(os.path.join(folder_path, filename), cv2.IMREAD_GRAYSCALE)
                images.append(resize_and_pad(image))
        return images

    def augment_images(self):
        augmented_images = []
        for image in self.images:
            angles = generate_unique_rotations(self.num_augmentations, self.rotation_range, min_angle_diff=0.3)
            for angle in angles:
                rotated_image = rotate_image(image, angle)
                bright_image = adjust_brightness(rotated_image, random.uniform(*self.brightness_range))
                cropped_image = random_crop(bright_image, self.crop_size)
                augmented_images.append((cropped_image, angle))
        return augmented_images

    def __len__(self):
        return len(self.augmented_data)

    def __getitem__(self, idx):
        image, angle = self.augmented_data[idx]
        return torch.tensor(image, dtype=torch.float32).unsqueeze(0) / 255.0, torch.tensor(angle, dtype=torch.float32)

# 추가 함수들
def generate_unique_rotations(num_rotations, rotation_range=(-50, 50), min_angle_diff=1.5):
    angles = []
    while len(angles) < num_rotations:
        angle = random.uniform(*rotation_range)
        if all(abs(angle - a) >= min_angle_diff for a in angles):
            angles.append(angle)
    return angles

def adjust_brightness(image, factor):
    return cv2.convertScaleAbs(image, alpha=factor, beta=0)

def random_crop(image, crop_size=(100, 100)):
    h, w = image.shape[:2]
    crop_h, crop_w = crop_size
    if h > crop_h and w > crop_w:
        top = random.randint(0, h - crop_h)
        left = random.randint(0, w - crop_w)
        return image[top:top + crop_h, left:left + crop_w]
    return image

# 학습 함수
def train_model(model, train_loader, num_epochs=40, tolerance=1.0):
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    model.train()
    for epoch in range(num_epochs):
        running_loss, correct_predictions, total_predictions = 0.0, 0, 0
        for images, angles in train_loader:
            images, angles = images.to(device), angles.to(device)
            optimizer.zero_grad()
            outputs = model(images).squeeze()
            loss = criterion(outputs, angles)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            diff = torch.abs(outputs - angles)
            correct_predictions += torch.sum(diff <= tolerance).item()
            total_predictions += len(angles)
        
        accuracy = (correct_predictions / total_predictions) * 100
        print(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}, Accuracy: {accuracy:.2f}%")

    save_path_for_para = '/home/jovyan/Rotation_new20_Resnet18_e40_a30testest.pth'
    os.makedirs(os.path.dirname(save_path_for_para), exist_ok=True)
    torch.save(model.state_dict(), save_path_for_para)
    print(f"모델이 '{save_path_for_para}'에 저장되었습니다.")

# 테스트 및 결과 저장 함수
def test_and_save_images(model, test_folder, save_path='results'):
    corrected_path = os.path.join(save_path, 'corrected_images')
    rotated_path = os.path.join(save_path, 'rotated_images')
    os.makedirs(corrected_path, exist_ok=True)
    os.makedirs(rotated_path, exist_ok=True)
    model.eval()
    with torch.no_grad():
        for filename in os.listdir(test_folder):
            if filename.endswith(('.png', '.jpg', '.jpeg','.JPG')):
                image_path = os.path.join(test_folder, filename)
                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
                image = resize_and_pad(image)
                image_tensor = torch.tensor(image, dtype=torch.float32).unsqueeze(0).unsqueeze(0) / 255.0
                image_tensor = image_tensor.to(device)
                predicted_angle = model(image_tensor).item()
                corrected_image = rotate_image(image, -predicted_angle)
                save_filename = os.path.join(corrected_path, f"{filename.split('.')[0]}_corrected.png")
                cv2.imwrite(save_filename, corrected_image)
                print(f"{filename} - Predicted Angle: {predicted_angle:.2f}")

# 데이터셋 및 모델 초기화
train_loader = DataLoader(RotNetDataset('/home/jovyan/gen_new_train_images'), batch_size=32, shuffle=True)

# 모델 학습
train_model(model, train_loader)

# 테스트 및 결과 저장
test_and_save_images(model, '/home/jovyan/test_image', save_path='resnet18_resultstestest')
