from ultralytics import YOLO
import pytesseract
import cv2
import re
import os

# YOLO 모델 로드 (학습된 가중치 사용)
weight_path = '/home/jovyan/data-vol-1/Result/2_Measure/YOLO/WB/YOLO_WB.pt'  # 학습된 가중치 파일 경로
model = YOLO(weight_path)

# OCR 설정 및 나노미터 단위 텍스트 필터링 정규 표현식
nm_pattern = re.compile(r'(\d{2,3})\s*nm')  # 2~3자리 숫자 뒤에 "nm"이 오는 형식

# 나노미터 측정 텍스트 인식 함수
def detect_nm_text(image, bbox):
    x1, y1, x2, y2 = map(int, bbox)
    roi = image[y1:y2, x1:x2]  # 바운딩 박스 영역 선택
    text = pytesseract.image_to_string(roi)
    match = nm_pattern.search(text)
    if match:
        return int(match.group(1))  # "nm" 단위 앞의 숫자를 반환
    return None

# 테스트 및 결과 저장 함수
def test_yolo_with_ocr(model, test_image_folder, output_folder):
    results_folder = os.path.join(output_folder, 'test_results')
    os.makedirs(results_folder, exist_ok=True)

    txt_output_path = os.path.join(results_folder, 'detection_results.txt')

    # 테스트 이미지 처리
    results = model.predict(
        source=test_image_folder,  # 테스트 이미지 폴더
        save=True,                 # 결과 이미지를 저장
        project=output_folder,     # 저장할 기본 디렉토리
        name="test_results"        # 결과 저장할 하위 폴더 이름
    )
    print(f"Test results saved to: {results_folder}")

    # 결과 TXT 파일 생성
    with open(txt_output_path, 'w') as txt_file:
        for result in results:
            image_name = os.path.basename(result.path)
            image = cv2.imread(result.path, cv2.IMREAD_GRAYSCALE)
            image_height, image_width = image.shape[:2]

            # 이미지 크기 기록
            txt_file.write(f"Image: {image_name}, Size: {image_width}x{image_height}\n")

            for box in result.boxes:  # 탐지된 모든 바운딩 박스에 대해
                class_id = int(box.cls)  # 클래스 ID
                bbox = box.xyxy[0].tolist()  # 바운딩 박스 좌표
                w_pixels = bbox[2] - bbox[0]
                h_pixels = bbox[3] - bbox[1]

                # 바운딩 박스 내 텍스트에서 "nm" 단위 필터링
                nm_value = detect_nm_text(image, bbox)
                if nm_value is not None:
                    # 나노미터 기준 비례 계산
                    w_nm = nm_value
                    h_nm = h_pixels * (w_nm / w_pixels)

                    # 결과 기록
                    txt_file.write(
                        f"Class: {class_id}, BBox: {bbox}, W_pixels: {w_pixels}, H_pixels: {h_pixels}, "
                        f"W_nm: {w_nm}, H_nm: {h_nm:.2f}\n"
                    )
                else:
                    # nm 단위 텍스트가 없을 경우 픽셀 단위만 기록
                    txt_file.write(
                        f"Class: {class_id}, BBox: {bbox}, W_pixels: {w_pixels}, H_pixels: {h_pixels}, "
                        "W_nm: None, H_nm: None\n"
                    )
    print(f"Detection results saved to: {txt_output_path}")

# 실행 예제
test_image_folder = '/home/jovyan/data-vol-1/dataset_WB/test/images'  # 테스트 이미지 폴더 경로
output_folder = '/home/jovyan/data-vol-1/Result/2_Measure/YOLO/WB'
test_yolo_with_ocr(model, test_image_folder, output_folder)
