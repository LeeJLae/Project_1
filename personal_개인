import os
import torch
import json
from torch.utils.data import Dataset, DataLoader
from segment_anything import sam_model_registry, SamPredictor
from torchvision import transforms
from torchvision.transforms import functional as F
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import PIL
import random
from torch.optim.lr_scheduler import StepLR

# 1. 데이터셋 클래스 정의
class MaskDataset(Dataset):
    def __init__(self, image_dir, mask_dir, json_dir, transform=None, rotation_range=(-60, 60)):
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.json_dir = json_dir
        self.transform = transform
        self.rotation_range = rotation_range
        self.image_files = sorted(os.listdir(image_dir))
        self.mask_files = sorted(os.listdir(mask_dir))
        self.json_files = sorted(os.listdir(json_dir))
    
    def __len__(self):
        return len(self.image_files)  # 이미지 파일 개수 기준으로 데이터셋 길이 반환
    
    def rotate_coordinates(self, measurement, angle, image_size):
        """ JSON 내 좌표 정보를 이미지 회전에 맞춰 변환 """
        w, h = image_size
        angle_rad = np.radians(angle)
        cx, cy = w / 2, h / 2  # 이미지 중심

        rotated_measurement = []

        for item in measurement:
            # 각 객체가 'points' 키를 포함하는지 확인
            if 'points' in item:
                rotated_item = item.copy()
                rotated_points = []
                for point in item['points']:
                    x, y = point['x'], point['y']
                    # 회전 변환
                    x_rot = cx + np.cos(angle_rad) * (x - cx) - np.sin(angle_rad) * (y - cy)
                    y_rot = cy + np.sin(angle_rad) * (x - cx) + np.cos(angle_rad) * (y - cy)
                    rotated_points.append({"x": x_rot, "y": y_rot})
                rotated_item['points'] = rotated_points
                rotated_measurement.append(rotated_item)
            else:
                # 'points' 키가 없는 경우 그대로 추가
                rotated_measurement.append(item)
        
        return rotated_measurement
    
    def __getitem__(self, idx):
        image_path = os.path.join(self.image_dir, self.image_files[idx])
        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])
        json_path = os.path.join(self.json_dir, self.json_files[idx])
        
        image = Image.open(image_path).convert("RGB")
        mask = Image.open(mask_path).convert("L")
        with open(json_path, 'r') as f:
            measurement = json.load(f)

        # Data Augmentation: Random Rotation
        angle = random.uniform(self.rotation_range[0], self.rotation_range[1])
        image = F.rotate(image, angle)
        mask = F.rotate(mask, angle)
        measurement = self.rotate_coordinates(measurement, angle, image.size)

        # 크기 조정 (Pillow의 Resampling.LANCZOS 사용)
        target_size = (256, 256)
        image = image.resize(target_size, PIL.Image.Resampling.LANCZOS)
        mask = mask.resize(target_size, PIL.Image.Resampling.LANCZOS)

        # 이미지 및 마스크 텐서 변환
        if self.transform:
            image = self.transform(image)
            mask = self.transform(mask)

        mask = mask.float()

        return image, mask, measurement

# 커스텀 collate_fn 정의
def collate_fn(batch):
    images, masks, measurements = zip(*batch)
    images = torch.stack(images)
    masks = torch.stack(masks)
    return images, masks, measurements

# 2. 모델 초기화 및 프리트레인된 가중치 로드
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_type = "vit_b"
model = sam_model_registry[model_type](checkpoint="/home/jovyan/SAM/sam_vit_b_01ec64.pth").to(device)

# 3. SamPredictor 초기화
predictor = SamPredictor(model)

# 4. 데이터 로더 정의
transform = transforms.Compose([
    transforms.ToTensor()
])

# 사용자 지정 데이터셋 경로 설정
train_image_dir = "/home/jovyan/data-vol-1/Y_T_Result/SAM_Train/image"
train_mask_dir = "/home/jovyan/data-vol-1/Y_T_Result/SAM_Train/mask"
train_json_dir = "/home/jovyan/data-vol-1/Y_T_Result/SAM_Train/measure"

train_dataset = MaskDataset(train_image_dir, train_mask_dir, train_json_dir, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)

# 5. 손실 함수 및 최적화기 설정
criterion = torch.nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
scheduler = StepLR(optimizer, step_size=10, gamma=0.5)  # 10 epoch마다 lr 감소

# 6. 학습 루프
num_epochs = 50
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for images, masks, measurements in train_loader:
        images, masks = images.to(device), masks.to(device)
        
        # 마스크의 채널을 1로 줄이고, float 타입으로 변환
        masks = masks.mean(dim=1, keepdim=True).float()

        optimizer.zero_grad()
        
        # 이미지 전처리 및 모델 예측
        predictions = []
        for i in range(images.size(0)):
            image = images[i].permute(1, 2, 0).cpu().numpy()
            predictor.set_image(image)  # 개별 이미지 전처리
            
            prediction = predictor.predict(multimask_output=False)
            if isinstance(prediction, tuple):
                prediction = prediction[0]
            
            pred_tensor = torch.tensor(prediction, device=device, dtype=torch.float32, requires_grad=True)
            predictions.append(pred_tensor)
        
        outputs = torch.stack(predictions).float()
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
    
    scheduler.step()  # 학습률 조정
    print(f"에포크 {epoch+1}/{num_epochs}, 손실: {running_loss/len(train_loader)}")

# 모델 파라미터 저장 경로 설정
model_params_save_path = "/home/jovyan/data-vol-1/Y_T_Result/SAM_Result/test2/sam_model_parameters.pth"
torch.save(model.state_dict(), model_params_save_path)
print(f"모델 파라미터가 '{model_params_save_path}'에 저장되었습니다.")

# 7. 테스트 및 결과 저장 함수 정의
def save_test_results(model, test_image_dir, test_mask_dir, test_json_dir, output_dir):
    test_dataset = MaskDataset(test_image_dir, test_mask_dir, test_json_dir, transform=transform)
    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)
    
    model.eval()
    os.makedirs(output_dir, exist_ok=True)
    
    predictor = SamPredictor(model)
    
    with torch.no_grad():
        for i, (image, mask, measurement) in enumerate(test_loader):
            image_np = image.squeeze(0).permute(1, 2, 0).cpu().numpy()
            predictor.set_image(image_np)
            
            output = predictor.predict(multimask_output=False)
            output = output[0]
            
            output_image = output.squeeze()
            plt.imshow(output_image, cmap='gray')
            plt.savefig(os.path.join(output_dir, f"result_{i}.png"))
            
            measurement_path = os.path.join(output_dir, f"measurement_{i}.txt")
            with open(measurement_path, 'w') as f:
                json.dump(measurement, f)
            
            print(f"결과 이미지 및 계측 파일이 {output_dir}에 저장되었습니다.")

# 8. 테스트 실행 및 결과 저장
test_image_dir = "/home/jovyan/data-vol-1/Y_T_Result/SAM_Test/image"
test_mask_dir = "/home/jovyan/data-vol-1/Y_T_Result/SAM_Test/mask"
test_json_dir = "/home/jovyan/data-vol-1/Y_T_Result/SAM_Test/measure"
output_results_dir = "/home/jovyan/data-vol-1/Y_T_Result/SAM_Result/test3"

save_test_results(model, test_image_dir, test_mask_dir, test_json_dir, output_results_dir)
