
# debug mask는 만들어지는데... 왜 훈련이 제대로 안되는지 확인해볼 것

import yaml
import torch
from torch.utils.data import Dataset, DataLoader
import xml.etree.ElementTree as ET
import cv2
import numpy as np
import os
from segment_anything import sam_model_registry, SamPredictor
from PIL import Image
import torchvision.transforms as transforms

# YAML 파일 불러오기 함수
def load_config(yaml_path):
    with open(yaml_path, 'r') as file:
        config = yaml.safe_load(file)
    return config

# 이미지 전처리 함수 (알파 채널 제거 및 1024x1024 RGB로 변환)
def preprocess_image_for_sam(image):
    if isinstance(image, torch.Tensor):
        return image.unsqueeze(0)
    
    if isinstance(image, np.ndarray):
        image = Image.fromarray(image)
    image = image.convert("RGB")
    
    transform = transforms.Compose([
        transforms.Resize((1024, 1024)),
        transforms.ToTensor()
    ])
    
    tensor_image = transform(image).unsqueeze(0)
    return tensor_image

# Class XML 파일에서 polygon 정보를 사용하여 마스크 생성
def class_xml_to_mask(class_xml_path, image_shape, debug_folder="debug_masks"):
    # XML 파일인지 확인
    if not class_xml_path.endswith('.xml'):
        print(f"Skipping non-XML file: {class_xml_path}")
        return np.zeros(image_shape[:2], dtype=np.uint8)
    
    # 파일이 비어 있는지 확인
    if os.path.getsize(class_xml_path) == 0:
        print(f"Skipping empty file: {class_xml_path}")
        return np.zeros(image_shape[:2], dtype=np.uint8)
    
    try:
        tree = ET.parse(class_xml_path)
        root = tree.getroot()
        mask = np.zeros(image_shape[:2], dtype=np.uint8)
        
        for obj in root.findall('object'):
            polygon_tag = obj.find('polygon')
            
            if polygon_tag is None:
                print(f"Warning: 'polygon' tag not found in {class_xml_path}")
                continue
            
            polygon = [(int(pt.find('x').text), int(pt.find('y').text)) for pt in polygon_tag]
            
            if polygon:
                polygon_array = np.array([polygon], dtype=np.int32)
                cv2.fillPoly(mask, polygon_array, 255)
            else:
                print(f"Warning: No valid polygon coordinates in {class_xml_path}")
        
        # 디버그 폴더에 마스크 이미지 저장
        os.makedirs(debug_folder, exist_ok=True)
        debug_path = os.path.join(debug_folder, f"{os.path.splitext(os.path.basename(class_xml_path))[0]}_mask_debug.png")
        cv2.imwrite(debug_path, mask)
        
        return mask

    except ET.ParseError as e:
        print(f"Error parsing XML file {class_xml_path}: {e}")
        return np.zeros(image_shape[:2], dtype=np.uint8)

# AugmentedDataset 클래스 정의
class AugmentedDataset(Dataset):
    def __init__(self, image_dir, class_xml_dir, measure_xml_dir, resize_shape=(1024, 1024)):
        self.image_paths = [f"{image_dir}/{file}" for file in sorted(os.listdir(image_dir))]
        self.class_xml_paths = [f"{class_xml_dir}/{file}" for file in sorted(os.listdir(class_xml_dir))]
        self.measure_xml_paths = [f"{measure_xml_dir}/{file}" for file in sorted(os.listdir(measure_xml_dir))]
        self.resize_shape = resize_shape
        self.transform = transforms.Compose([
            transforms.Resize(self.resize_shape),
            transforms.ToTensor()
        ])

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image = self.load_image(self.image_paths[idx])
        image = self.transform(image)
        measure_mask = class_xml_to_mask(self.class_xml_paths[idx], (1024, 1024))
        measure_mask = torch.tensor(measure_mask, dtype=torch.float32) / 255.0
        measurement = self.parse_measurement_xml(self.measure_xml_paths[idx])
        
        return image, measure_mask, measurement

    def load_image(self, path):
        return Image.open(path).convert("RGB")

    def parse_measurement_xml(self, xml_path):
        tree = ET.parse(xml_path)
        root = tree.getroot()
        measurement_data = {}
        for measure in root.findall('measurement'):
            name = measure.find('name').text
            value = float(measure.find('value').text)
            measurement_data[name] = value
        return measurement_data

# SAM 모델 로드 함수
def load_sam_model(weight_path, model_type='vit_h'):
    model = sam_model_registry[model_type](checkpoint=weight_path)
    predictor = SamPredictor(model)
    return predictor

# 학습 함수 정의
def train_sam_with_measurement(predictor, dataloader, epochs, learning_rate=1e-4, device='cuda'):
    optimizer = torch.optim.Adam(predictor.model.parameters(), lr=learning_rate)
    criterion_seg = torch.nn.BCEWithLogitsLoss()
    criterion_measure = torch.nn.MSELoss()
    
    predictor.model.to(device)
    
    for epoch in range(epochs):
        predictor.model.train()
        epoch_loss_seg, epoch_loss_measure = 0, 0
        for images, masks, measurements in dataloader:
            images = [img.to(device) for img in images]
            masks = masks.to(device)
            optimizer.zero_grad()
            
            # 데이터 확인
            # print(f"Mask unique values: {torch.unique(masks)}")
            # print(f"Measurements: {measurements}")

            # 손실 초기화
            loss_seg_total = torch.tensor(0.0, device=device, requires_grad=True)
            loss_measure_total = torch.tensor(0.0, device=device, requires_grad=True)
            
            for img, mask, measurement in zip(images, masks, measurements):
                preprocessed_image = preprocess_image_for_sam(img).squeeze(0).to(device)
                
                predictor.set_image(preprocessed_image)
                
                predictions, _, _ = predictor.predict(multimask_output=False)

                # 예측 범위 확인
                # print(f"Predictions min: {predictions.min()}, max: {predictions.max()}")

                loss_seg = criterion_seg(predictions, mask.unsqueeze(0))
                predicted_measurement = predictions.mean(dim=[1, 2, 3])
                measurement_tensor = torch.tensor([measurement], dtype=torch.float32, requires_grad=True).to(device)
                loss_measure = criterion_measure(predicted_measurement, measurement_tensor)
                
                loss_seg_total = loss_seg_total + loss_seg
                loss_measure_total = loss_measure_total + loss_measure
            
            total_loss = loss_seg_total + loss_measure_total
            total_loss.backward()
            optimizer.step()

            epoch_loss_seg += loss_seg_total.item()
            epoch_loss_measure += loss_measure_total.item()
        
        print(f"Epoch {epoch+1}/{epochs}, Segmentation Loss: {epoch_loss_seg/len(dataloader)}, Measurement Loss: {epoch_loss_measure/len(dataloader)}")

# 테스트 함수 정의
def test_sam_with_image_only(predictor, image_folder, output_folder, device='cuda'):
    predictor.model.eval()
    os.makedirs(output_folder, exist_ok=True)
    
    with torch.no_grad():
        for image_name in os.listdir(image_folder):
            image_path = os.path.join(image_folder, image_name)
            image = Image.open(image_path).convert("RGB")
            if image is None:
                continue
            
            preprocessed_image = preprocess_image_for_sam(image).squeeze(0).to(device)
            predictor.set_image(preprocessed_image)
            prediction, _, _ = predictor.predict(multimask_output=False)
            
            # 예측 결과 범위 및 크기 확인
            # print(f"Prediction min: {prediction.min()}, max: {prediction.max()}, mean: {prediction.mean()}")
            # print(f"Prediction shape: {prediction.shape}")
            
            if isinstance(prediction, torch.Tensor):
                prediction_image = (prediction * 255).cpu().numpy().astype(np.uint8)
            else:
                prediction_image = (prediction * 255).astype(np.uint8)
            
            prediction_image = prediction_image.squeeze()
            
            mask_output_path = os.path.join(output_folder, f"{os.path.splitext(image_name)[0]}_mask.png")
            Image.fromarray(prediction_image).save(mask_output_path)
            
            # 측정 결과 저장
            measurement_prediction = prediction.mean()
            with open(os.path.join(output_folder, f"{os.path.splitext(image_name)[0]}_measurement.txt"), 'w') as f:
                f.write(f"Predicted Measurement: {measurement_prediction:.4f}\n")
            
            print(f"Processed {image_name}: Measurement saved at {mask_output_path}")

# 전체 실행 함수
def main():
    config = load_config('/home/jovyan/jonglae/Retry1/Segmentation/data_config.yaml')
    
    predictor = load_sam_model(config['model']['weight_path'], config['model']['model_type'])

    train_dataset = AugmentedDataset(
        image_dir=config['data']['image_dir'],
        class_xml_dir=config['data']['class_xml_dir'],
        measure_xml_dir=config['data']['measure_xml_dir']
    )
    train_dataloader = DataLoader(train_dataset, batch_size=config['train']['batch_size'], shuffle=True)
    train_sam_with_measurement(
        predictor, 
        train_dataloader, 
        epochs=config['train']['epochs'], 
        learning_rate=config['train']['learning_rate'], 
        device='cuda'
    )
    
    test_image_folder = config['data']['test_image_dir']
    output_folder = config['data']['output_dir']
    test_sam_with_image_only(predictor, test_image_folder, output_folder, device='cuda')

if __name__ == "__main__":
    main()
