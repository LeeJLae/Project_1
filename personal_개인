import torch
import torch.nn as nn
import torch.optim as optim
import cv2
import os
from torch.utils.data import DataLoader, Dataset
import numpy as np
from torchvision import transforms
from PIL import Image
import json

# SAM Model definition
class SAMModel(nn.Module):
    def __init__(self):
        super(SAMModel, self).__init__()
        self.encoder = nn.Conv2d(3, 64, kernel_size=3, padding=1)
        self.decoder = nn.Conv2d(64, 1, kernel_size=3, padding=1)

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

def load_sam_model(weight_path):
    model = SAMModel()
    checkpoint = torch.load(weight_path, map_location='cpu')
    model.load_state_dict(checkpoint, strict=False)
    print("Model successfully loaded.")
    return model

# Dataset class for SAM with measurements
class SAMDatasetWithMeasurements(Dataset):
    def __init__(self, image_folder, mask_folder, json_folder, transform=None, max_line_widths=10):
        self.image_folder = image_folder
        self.mask_folder = mask_folder
        self.json_folder = json_folder
        self.transform = transform
        self.max_line_widths = max_line_widths  # 고정된 길이 설정
        self.image_files = sorted([f for f in os.listdir(image_folder) if f.endswith('.png')])

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        image_path = os.path.join(self.image_folder, self.image_files[idx])
        mask_path = os.path.join(self.mask_folder, self.image_files[idx].replace('.png', '_mask.png'))
        json_path = os.path.join(self.json_folder, self.image_files[idx].replace('.png', '.json'))

        # 이미지 로드 및 PIL 변환
        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = Image.fromarray(image)  # numpy 이미지를 PIL로 변환

        # 마스크 로드 및 PIL 변환
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if mask is None:
            raise FileNotFoundError(f"Mask not found for {mask_path}")
        mask = Image.fromarray(mask)  # numpy 마스크를 PIL로 변환

        # transform 적용
        if self.transform:
            image = self.transform(image)
            mask = self.transform(mask)

        # JSON에서 계측 정보 로드 및 고정 길이로 패딩
        with open(json_path, 'r') as f:
            data = json.load(f)
            line_widths = [item.get('line_width', 1.0) for item in data]
        
        # line_widths를 max_line_widths 길이로 패딩 또는 자르기
        if len(line_widths) > self.max_line_widths:
            line_widths = line_widths[:self.max_line_widths]
        else:
            line_widths.extend([0] * (self.max_line_widths - len(line_widths)))

        return image, mask, torch.tensor(line_widths, dtype=torch.float32)

# Training and testing function
def train_and_test_sam(model, train_loader, test_loader, num_epochs, save_folder):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    criterion = nn.BCEWithLogitsLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # Training loop
    for epoch in range(num_epochs):
        model.train()
        total_loss = 0
        for images, masks, line_widths in train_loader:
            images, masks = images.to(device), masks.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, masks)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}")

        # Save model periodically
        if (epoch + 1) % 5 == 0:
            torch.save(model.state_dict(), os.path.join(save_folder, f'sam_model_epoch_{epoch+1}.pth'))

    # Testing loop
    model.eval()
    os.makedirs(save_folder, exist_ok=True)
    with torch.no_grad():
        for idx, (images, masks, line_widths) in enumerate(test_loader):
            images = images.to(device)
            outputs = model(images)
            output_mask = torch.sigmoid(outputs).cpu().numpy()[0, 0] > 0.5
            output_mask = (output_mask * 255).astype(np.uint8)
            output_path = os.path.join(save_folder, f'test_output_{idx}.png')
            cv2.imwrite(output_path, output_mask)
            print(f"Saved test result to {output_path}")

# Paths and hyperparameters
image_folder = '/home/jovyan/data-vol-1/Y_T_Result/SAM_Train/image'
mask_folder = '/home/jovyan/data-vol-1/Y_T_Result/SAM_Train/mask'
json_folder = '/home/jovyan/data-vol-1/Y_T_Result/SAM_Train/measure'
weight_path = '/home/jovyan/SAM/sam_vit_b_01ec64.pth'
save_folder = '/home/jovyan/data-vol-1/Y_T_Result/SAM_Result/test2'
num_epochs = 10

# DataLoader setup
fixed_size = (256, 256)

# transform에 Resize 추가
transform = transforms.Compose([
    transforms.Resize(fixed_size),  # 이미지 크기를 고정합니다.
    transforms.ToTensor()
])

train_dataset = SAMDatasetWithMeasurements(image_folder, mask_folder, json_folder, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
test_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)

# Load model and execute train/test
sam_model = load_sam_model(weight_path)
train_and_test_sam(sam_model, train_loader, test_loader, num_epochs=num_epochs, save_folder=save_folder)
