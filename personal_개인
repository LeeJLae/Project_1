import cv2
import re
import os
import torch
import sys

# 절대 경로 지정

MODULE_PATH = '/home/jovyan/STN/EasyOCR/easyocr'
WEIGHT_PATH = '/home/jovyan/data-vol-1/Result/2_Measure/YOLO/WB/YOLO_WB.pt'
RECOGNITION_WEIGHT_PATH = '/home/jovyan/jonglae/Retry1/Main/MODE_0_OCR_WB_YOLO/OCR/craft_mlt_25k.pth'

# EasyOCR detection 및 recognition 파일 불러오기
sys.path.append(MODULE_PATH)

from detection import get_textbox, get_detector  # DETECTION에서 감지 함수 가져오기
from recognition import get_text, get_recognizer  # RECOGNITION에서 OCR 함수 가져오기

# YOLO 모델 초기화
device = 'cuda' if torch.cuda.is_available() else 'cpu'
detector = get_detector(WEIGHT_PATH, device=device)

# OCR 모델 초기화
character = '0123456789nm'  # OCR에 사용할 문자 집합
recognizer, converter = get_recognizer(
    recog_network='generation1',
    network_params={'input_channel': 1, 'output_channel': 512, 'hidden_size': 256},
    character=character,
    separator_list=[],
    dict_list=[],
    model_path=RECOGNITION_WEIGHT_PATH,
    device=device
)

def process_yolo_and_ocr(image, detector, recognizer, converter):
    """
    YOLO 데이터를 OBB 형식으로 처리하고, OCR로 나노미터 기준값 추출
    """
    output = []

    # YOLO 감지 결과 가져오기
    yolo_data = get_textbox(
        detector, image, canvas_size=1280, mag_ratio=1.5,
        text_threshold=0.7, link_threshold=0.4, low_text=0.4,
        poly=False, device=device
    )

    for polys in yolo_data:
        for poly in polys:
            class_id = 0  # 예시: Class 0으로 설정
            coords = poly  # 좌표는 OBB 형식의 8개 좌표

            # OCR 수행
            min_x, max_x = min(coords[0::2]), max(coords[0::2])
            min_y, max_y = min(coords[1::2]), max(coords[1::2])
            cropped_image = image[min_y:max_y, min_x:max_x]
            ocr_result = get_text(
                character=character, imgH=32, imgW=100,
                recognizer=recognizer, converter=converter,
                image_list=[((0, 0), cropped_image)], device=device
            )

            # OCR 결과에서 나노미터 값 추출
            text, confidence = ocr_result[0][1], ocr_result[0][2]
            nm_value = re.search(r'\d+ ?nm', text)
            nm_value = nm_value.group() if nm_value else "N/A"

            # 결과 형식에 맞게 추가
            if class_id == 0:
                output.append(f"{class_id} " + " ".join(map(str, coords)))
            else:
                output.append(f"Class 1 ({nm_value})")

    return output

def process_folder(input_folder, output_folder):
    """
    폴더 내의 모든 이미지에 대해 YOLO 데이터 처리 및 결과 저장
    """
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
    
    for filename in os.listdir(input_folder):
        if filename.endswith(('.jpg', '.png')):
            image_path = os.path.join(input_folder, filename)
            image = cv2.imread(image_path)
            
            # YOLO 및 OCR 처리
            processed_output = process_yolo_and_ocr(image, detector, recognizer, converter)
            
            # 결과를 텍스트 파일에 저장
            output_path = os.path.join(output_folder, f"{filename.split('.')[0]}_output.txt")
            with open(output_path, 'w') as f:
                for line in processed_output:
                    f.write(line + '\n')

# 입력 및 출력 폴더 경로
input_folder = '/home/jovyan/data-vol-1/dataset_WB/test/images'
output_folder = '/home/jovyan/data-vol-1/Result/2_Measure/YOLO/WB'

# 폴더 내 이미지 처리 시작
process_folder(input_folder, output_folder)
