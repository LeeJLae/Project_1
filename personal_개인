Traceback (most recent call last):
  File "/home/jovyan/jonglae/Retry1/Segmentation/222.py", line 159, in <module>
    save_test_results(model, test_image_dir, test_mask_dir, test_json_dir, output_results_dir)
  File "/home/jovyan/jonglae/Retry1/Segmentation/222.py", line 138, in save_test_results
    predictor.set_image(image.cpu().numpy())
  File "/home/jovyan/SAM_Model/segment_anything/predictor.py", line 56, in set_image
    input_image = self.transform.apply_image(image)
  File "/home/jovyan/SAM_Model/segment_anything/utils/transforms.py", line 31, in apply_image
    return np.array(resize(to_pil_image(image), target_size))
  File "/home/jovyan/.conda/envs/aipbase/lib/python3.10/site-packages/torchvision/transforms/functional.py", line 274, in to_pil_image
    raise ValueError(f"pic should be 2/3 dimensional. Got {pic.ndim} dimensions.")
ValueError: pic should be 2/3 dimensional. Got 4 dimensions.
