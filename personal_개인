import os
import torch
from torch.optim import Adam
from torch.utils.data import DataLoader, Dataset
from torchvision.transforms import ColorJitter, functional as TF
from segment_anything import sam_model_registry, SamAutomaticMaskGenerator
from PIL import Image
import numpy as np
import json

# GPU 설정
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 경로 설정
IMAGE_DIR = "/home/jovyan/data-vol-1/dataset_SAM/train/image"
TXT_DIR = "/home/jovyan/data-vol-1/dataset_SAM/train/Class_txt"
JSON_DIR = "/home/jovyan/data-vol-1/dataset_SAM/train/measure"
OUTPUT_DIR = "/home/jovyan/data-vol-1/Result/2_Measure/SAM/test"
MODEL_SAVE_PATH = "/home/jovyan/data-vol-1/Result/2_Measure/SAM/BB_weight_SAM/SAM_FineTune2.pth"  # 가중치 저장 경로

# SAM 모델 로드 (ViT-B)
sam_checkpoint_path = "/home/jovyan/SAM/sam_vit_b_01ec64.pth"
sam_model = sam_model_registry["vit_b"](checkpoint=sam_checkpoint_path).to(device)

# 학습 하이퍼파라미터
num_epochs = 10
learning_rate = 1e-4
batch_size = 4
optimizer = Adam(sam_model.parameters(), lr=learning_rate)

# IoU 손실 계산 함수
def compute_iou_loss(pred_mask, true_mask):
    intersection = torch.logical_and(pred_mask, true_mask).float().sum()
    union = torch.logical_or(pred_mask, true_mask).float().sum()
    iou = intersection / (union + 1e-6)  # 분모가 0이 되지 않도록 작은 값을 더함
    return (1 - iou).requires_grad_(True)  # requires_grad 설정

# 데이터셋 클래스 정의
class CustomDataset(Dataset):
    def __init__(self, image_dir, txt_dir, json_dir, transform=None):
        self.image_dir = image_dir
        self.txt_dir = txt_dir
        self.json_dir = json_dir
        self.image_files = [f for f in os.listdir(image_dir) if f.endswith(".jpg") or f.endswith(".png")]
        self.transform = transform

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        image_file = self.image_files[idx]
        image_path = os.path.join(self.image_dir, image_file)
        txt_path = os.path.join(self.txt_dir, image_file.replace(".jpg", ".txt").replace(".png", ".txt"))
        json_path = os.path.join(self.json_dir, image_file.replace(".jpg", ".json").replace(".png", ".json"))
        
        image = Image.open(image_path).convert("RGB")
        bboxes = load_bboxes(txt_path)
        measurements = parse_json(json_path)
        
        if self.transform:
            image, bboxes = self.transform(image, bboxes)

        image_np = np.array(image)
        return image_np, bboxes, measurements, image_file

# 데이터 증강 함수
def transform(image, bboxes):
    color_jitter = ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)
    image = color_jitter(image)
    
    rotated_bboxes = []
    for angle in range(-50, 51):  # -50도에서 50도까지 1도씩 회전
        rotated_image = TF.rotate(image, angle)
        
        for bbox in bboxes:
            # 바운딩 박스 회전 적용 (필요시 추가 코드 필요)
            # 회전에 따른 좌표 계산 로직 추가
            rotated_bboxes.append(bbox)  # 예시로 원래 bboxes 사용, 실제로는 좌표 계산 필요
        
    return rotated_image, rotated_bboxes

def train_sam():
    dataset = CustomDataset(IMAGE_DIR, TXT_DIR, JSON_DIR, transform=transform)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    mask_generator = SamAutomaticMaskGenerator(sam_model)

    for epoch in range(num_epochs):
        print(f"Epoch {epoch + 1}/{num_epochs}")
        running_loss = 0.0
        total_batches = len(dataloader)
        
        for batch_idx, (images, bboxes, measurements, image_files) in enumerate(dataloader):
            images = [torch.tensor(img).to(device) for img in images]
            
            batch_loss = 0.0
            for image, bbox, measurement, image_file in zip(images, bboxes, measurements, image_files):
                segmented_image, measurements_dict = perform_segmentation_and_measurement(mask_generator, image, bbox, measurement)
                true_mask = np.zeros_like(segmented_image)  # 실제 마스크 데이터 필요
                loss = compute_iou_loss(torch.tensor(segmented_image).to(device), torch.tensor(true_mask).to(device))
                batch_loss += loss.item()

                save_path = os.path.join(OUTPUT_DIR, f"segmented_{image_file}")
                Image.fromarray(segmented_image).save(save_path)

                output_json_path = os.path.join(OUTPUT_DIR, f"{image_file.replace('.jpg', '.json').replace('.png', '.json')}")
                with open(output_json_path, 'w') as f:
                    json.dump(measurements_dict, f)

            avg_loss = batch_loss / batch_size
            running_loss += avg_loss
            completion_percent = 100 * (batch_idx + 1) / total_batches
            print(f"[Epoch {epoch + 1}/{num_epochs}] - Batch: {batch_idx + 1}/{total_batches} - Loss: {avg_loss:.4f} - {completion_percent:.2f}% 완료")
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        print(f"Epoch {epoch + 1} 완료, 평균 손실: {running_loss / total_batches:.4f}")

    torch.save(sam_model.state_dict(), MODEL_SAVE_PATH)
    print(f"모델 가중치가 {MODEL_SAVE_PATH}에 저장되었습니다.")

def load_bboxes(txt_path):
    bboxes = []
    with open(txt_path, 'r') as f:
        for line in f:
            class_id, x, y, w, h = map(float, line.strip().split())
            bboxes.append({"class_id": int(class_id), "x": x, "y": y, "w": w, "h": h})
    return bboxes

def parse_json(json_path):
    with open(json_path, 'r') as f:
        measurements = json.load(f)
    return measurements

def perform_segmentation_and_measurement(mask_generator, image, bboxes, measurements):
    masks = mask_generator.generate(image)
    segmented_image = apply_masks_to_image(image, masks)
    
    measurements_dict = {}
    for bbox in bboxes:
        class_id = bbox["class_id"]
        x, y, w, h = bbox["x"], bbox["y"], bbox["w"], bbox["h"]
        measurements_dict[class_id] = {
            "position": (x, y),
            "width": w,
            "height": h,
            "measurements": measurements[class_id] if class_id < len(measurements) else 0
        }
    return segmented_image, measurements_dict

def apply_masks_to_image(image, masks):
    return image  # 현재는 입력 이미지를 그대로 반환

# 학습 시작
train_sam()
