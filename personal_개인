import os
import torch
import json
from torch.utils.data import Dataset, DataLoader
from segment_anything import sam_model_registry, SamPredictor
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import PIL

# 1. 데이터셋 클래스 정의
class MaskDataset(Dataset):
    def __init__(self, image_dir, mask_dir, json_dir, transform=None):
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.json_dir = json_dir
        self.transform = transform
        self.image_files = sorted(os.listdir(image_dir))
        self.mask_files = sorted(os.listdir(mask_dir))
        self.json_files = sorted(os.listdir(json_dir))
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        image_path = os.path.join(self.image_dir, self.image_files[idx])
        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])
        json_path = os.path.join(self.json_dir, self.json_files[idx])
        
        image = Image.open(image_path).convert("RGB")
        mask = Image.open(mask_path).convert("RGB")  # 마스크도 3채널로 변환

        # 크기 조정 (Pillow의 Resampling.LANCZOS 사용)
        target_size = (256, 256)  # 원하는 크기로 설정
        image = image.resize(target_size, PIL.Image.Resampling.LANCZOS)
        mask = mask.resize(target_size, PIL.Image.Resampling.LANCZOS)

        # 이미지 및 마스크 텐서 변환
        if self.transform:
            image = self.transform(image)  # 이미지 텐서화
            mask = self.transform(mask)  # 마스크 텐서화

        mask = mask.float()  # 마스크를 float32 타입으로 변환

        with open(json_path, 'r') as f:
            measurement = json.load(f)
        
        return image, mask, measurement

# 커스텀 collate_fn 정의
def collate_fn(batch):
    images, masks, measurements = zip(*batch)
    images = torch.stack(images)
    masks = torch.stack(masks)
    return images, masks, measurements

# 2. 모델 초기화 및 프리트레인된 가중치 로드
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_type = "vit_b"  # 사용할 모델의 타입
model = sam_model_registry[model_type](checkpoint="/home/jovyan/SAM/sam_vit_b_01ec64.pth").to(device)

# 3. SamPredictor 초기화
predictor = SamPredictor(model)

# 4. 데이터 로더 정의
transform = transforms.Compose([
    transforms.ToTensor()
])

# 사용자 지정 데이터셋 경로 설정
train_image_dir = "/home/jovyan/data-vol-1/Y_T_Result/SAM_Train/image"  # 학습 이미지 경로
train_mask_dir = "/home/jovyan/data-vol-1/Y_T_Result/SAM_Train/mask"     # 학습 마스크 경로
train_json_dir = "/home/jovyan/data-vol-1/Y_T_Result/SAM_Train/measure"     # 학습 JSON 경로

train_dataset = MaskDataset(train_image_dir, train_mask_dir, train_json_dir, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)

# 5. 손실 함수 및 최적화기 설정
criterion = torch.nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# 6. 학습 루프
num_epochs = 1
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for images, masks, measurements in train_loader:
        images, masks = images.to(device), masks.to(device)
        
        # 마스크의 채널을 1로 줄이고, float 타입으로 변환
        masks = masks.mean(dim=1, keepdim=True).float()

        optimizer.zero_grad()
        
        # 이미지 전처리 및 모델 예측
        predictions = []
        for i in range(images.size(0)):
            # 배치에서 개별 이미지 추출 후 (C, H, W) -> (H, W, C) 형식으로 변환
            image = images[i].permute(1, 2, 0).cpu().numpy()
            predictor.set_image(image)  # 개별 이미지 전처리
            
            prediction = predictor.predict(multimask_output=False)  # 모델 예측
            if isinstance(prediction, tuple):
                prediction = prediction[0]  # 첫 번째 반환값만 사용 (예: 마스크)
            
            # 예측을 float 텐서로 변환 및 requires_grad=True 설정
            pred_tensor = torch.tensor(prediction, device=device, dtype=torch.float32, requires_grad=True)
            predictions.append(pred_tensor)
        
        outputs = torch.stack(predictions).float()  # float 타입으로 변환
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
    
    print(f"에포크 {epoch+1}/{num_epochs}, 손실: {running_loss/len(train_loader)}")

# 모델 파라미터 저장 경로 설정
model_params_save_path = "/home/jovyan/data-vol-1/Y_T_Result/SAM_Result/test2/sam_model_parameters.pth"  # 저장할 경로 입력
torch.save(model.state_dict(), model_params_save_path)
print(f"모델 파라미터가 '{model_params_save_path}'에 저장되었습니다.")

# 7. 테스트 및 결과 저장 함수 정의
def save_test_results(model, test_image_dir, test_mask_dir, test_json_dir, output_dir):
    test_dataset = MaskDataset(test_image_dir, test_mask_dir, test_json_dir, transform=transform)
    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)
    
    model.eval()
    os.makedirs(output_dir, exist_ok=True)
    
    predictor = SamPredictor(model)
    
    with torch.no_grad():
        for i, (image, mask, measurement) in enumerate(test_loader):
            # 배치 차원을 제거하고 (H, W, C) 형식으로 변환
            image_np = image.squeeze(0).permute(1, 2, 0).cpu().numpy()
            predictor.set_image(image_np)  # 개별 이미지 전처리
            
            output = predictor.predict(multimask_output=False)  # 모델 예측
            output = output[0]  # 예측 결과의 첫 번째 값만 사용
            
            # 결과 이미지 및 계측 데이터 저장
            output_image = output.squeeze()  # 이미 numpy 형식이므로 cpu() 호출 불필요
            plt.imshow(output_image, cmap='gray')
            plt.savefig(os.path.join(output_dir, f"result_{i}.png"))
            
            # 계측 데이터 저장
            measurement_path = os.path.join(output_dir, f"measurement_{i}.txt")
            with open(measurement_path, 'w') as f:
                json.dump(measurement, f)
            
            print(f"결과 이미지 및 계측 파일이 {output_dir}에 저장되었습니다.")

# 8. 테스트 실행 및 결과 저장
test_image_dir = "/home/jovyan/data-vol-1/Y_T_Result/SAM_Test/image"   # 테스트 이미지 경로
test_mask_dir = "/home/jovyan/data-vol-1/Y_T_Result/SAM_Test/mask"     # 테스트 마스크 경로
test_json_dir = "/home/jovyan/data-vol-1/Y_T_Result/SAM_Test/measure"     # 테스트 JSON 경로
output_results_dir = "/home/jovyan/data-vol-1/Y_T_Result/SAM_Result/test2"  # 결과 저장 경로

save_test_results(model, test_image_dir, test_mask_dir, test_json_dir, output_results_dir)
